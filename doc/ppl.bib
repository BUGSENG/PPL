@PREAMBLE{ "\newcommand{\noopsort}[1]{}" }

@PhdThesis{Ancourt91th,
  Author = "C. Ancourt",
  Title = "G\'en\'eration automatique de codes de transfert
           pour multiprocesseurs \`a m\'emoires locales",
  School = "Universit\'e de Paris VI",
  Address = "Paris, France",
  Month = mar,
  Year = 1991,
  Abstract = "Parallel tasks generated by automatic parallelizers do
              not take advantage of supercomputer memory
              hierarchies. This thesis presents algorithms to
              transform a parallel task into an equivalent one that
              uses data with fast access memory. Algorithms to
              automatically generate code to move data between two
              different memory levels of (super)computer are
              presented. These copy codes should move back and forth
              array elements that are accessed when an elementary
              processor execute an array reference located in a set of
              loops. This set of array elements is characterized by a
              set of integer points in $\mathcal{Z}^p$ that is not
              necessarily a convex polyhedron.
              In the case of data transfers from global memory to
              local memory, it is possible to copy a superset of
              accessed elements, for instance its convex hull. A
              trade-off has to be made between local memory space,
              transfer volume and loop bound complexity.
              To copy data back from local memory to global memory is
              more difficult because global memory consistency must be
              preserved. Each processor (or processus) should only
              copy its own results to avoid errors and, secondarily,
              to decrease global memory traffic.
              The input of our main algorithm is an integer convex
              polyhedron defining the computation space and an affine
              function representing the index expressions. Its output
              is set of nested loops containing a new array reference
              whose execution copies exactly accessed elements. Each
              element is copied only once. Loop bound expressions use
              integer divisions to generate non-convex sets.
              For most practical programs this algorithm provides
              optimal code in number of data movements and control
              overhead. Associated with a dependence analysis phase,
              it can be used to generate data movements in distributed
              memory multiprocessors. When data partitionning in local
              memories is specified, it eliminates most of execution
              guards used to compute only local values on each
              processor."
}

@PhdThesis{Bagnara97th,
  Author = "R. Bagnara",
  Title  = "Data-Flow Analysis for Constraint Logic-Based Languages",
  School = "Dipartimento di Informatica, Universit\`a di Pisa",
  Address = "Pisa, Italy",
  Month = mar,
  Year   = 1997,
  Note = "Printed as Report TD-1/97",
  Abstract = "We aim at the the development of precise, practical, and
             theoretically well-founded data-flow analyzers for
             constraint logic-based languages. The design and
             development of such an analyzer fostered a number of
             research problems that we had to address. A hierarchy of
             constraint systems is introduced that is suitable for
             designing and combining abstract domains. The rational
             construction of a generic domain for the structural
             analysis of CLP programs is presented. We also address
             the problem of the ``missing \emph{occur-check}'' in many
             implemented languages.  We introduce a new family of
             domains, based on constraint propagation techniques, for
             the abstraction of the numerical leaves that occur in the
             terms of CLP languages. Despite the fact that groundness
             analysis for logic-based languages is a widely studied
             subject, a novel domain for groundness analysis is
             presented that outperforms the existing domains from
             several points of view. Finally, we present a bottom-up
             analysis technique for CLP languages that allows for the
             precise derivation of both call- and success-patterns
             preserving the connection between them."
}

@Article{Bagnara98SCP,
  Author = "R. Bagnara",
  Title = "A Hierarchy of Constraint Systems for Data-Flow Analysis
           of Constraint Logic-Based Languages",
  Journal = "Science of Computer Programming",
  Volume = 30,
  Number = "1--2",
  Year = 1998,
  Pages = "119--155",
  Abstract = "Many interesting analyses for constraint logic-based
              languages are aimed at the detection of \emph{monotonic}
              properties, that is to say, properties that are
              preserved as the computation progresses.  Our basic
              claim is that most, if not all, of these analyses can be
              described within a unified notion of constraint domains.
              We present a class of constraint systems that allows for
              a smooth integration within an appropriate framework for
              the definition of non-standard semantics of constraint
              logic-based languages.  Such a framework is also
              presented and motivated.  We then show how such domains
              can be built, as well as construction techniques that
              induce a hierarchy of domains with interesting
              properties.  In particular, we propose a general
              methodology for domain combination with asynchronous
              interaction (i.e., the interaction is not necessarily
              synchronized with the domains' operations).  By
              following this methodology, interesting combinations of
              domains can be expressed with all the the semantic
              elegance of concurrent constraint programming
              languages.",
  URL = "http://www.cs.unipr.it/ppl/Documentation/Bagnara98SCP.pdf"
}

@Misc{BagnaraDHMZ06a,
  Author = "R. Bagnara and K. Dobson and P. M. Hill and M. Mundell
            and E. Zaffanella",
  Title = "Grids: A Domain for Analyzing the Distribution of Numerical Values",
  Year = 2006,
  Note = "Accepted for publication and presented at the
          International Symposium on Logic-based Program Synthesis and
          Transformation.",
  Abstract = "This paper explores the abstract domain of grids,
          a domain that is able to represent sets of equally spaced
          points and hyperplanes over an n-dimensional vector space.
          Such a domain is useful for the static analysis of the
          patterns of distribution of the values program variables can
          take.  We present the domain, its representation and the
          basic operations on grids necessary to define the abstract
          semantics.  We show how the definition of the domain and its
          operations exploit well-known techniques from linear algebra
          as well as a dual representation that allows, among other
          things, for a concise and efficient implementation.",
  URL = "http://www.comp.leeds.ac.uk/hill/Papers/papers.html"
}

@Misc{BagnaraDHMZ06b,
  Author = "R. Bagnara and K. Dobson and P. M. Hill and M. Mundell
            and E. Zaffanella",
  Title = "A Practical Tool for Analyzing the Distribution
           of Numerical Values",
  Year = 2006,
  Note = "Submitted for publication.  Available at
         \url{http://www.comp.leeds.ac.uk/hill/Papers/papers.html}.",
  Abstract = "The abstract domain of grids (or lattices) is a domain
         that is able to represent sets of equally spaced points and
         hyperplanes over an n-dimensional vector space.  Such a
         domain is useful for the static analysis of the patterns of
         distribution of the values that program variables can take.
         This paper explores how this domain may be used in program
         analysis, describing grid operations such as affine image,
         affine preimage and widenings needed by such an application.
         The paper also shows how any grid may be approximated by a
         less precise non-relational grid and describes how such an
         approximation can be computed.  Illustrative examples show
         how the domain may be used in the analysis of programs
         containing simple assignment statements, while loops and
         recursive procedures."
}

@Misc{BagnaraHMZ04EA,
  Author = "R. Bagnara and P. M. Hill and E. Mazzi and E. Zaffanella",
  Title = "Widening Operators for Weakly-Relational Numeric Abstractions",
  Howpublished = "Report {\tt arXiv:cs.PL/0412043}",
  Year = 2004,
  Note = "Extended abstract.
          Contribution to the \emph{International workshop on
          ``Numerical \& Symbolic Abstract Domains''}
          (NSAD'05, Paris, January 21, 2005).
          Available at \url{http://arxiv.org/}
          and \url{http://www.cs.unipr.it/ppl/}",
  Abstract = "We discuss the divergence problems recently identified
              in some extrapolation operators for weakly-relational
              numeric domains. We identify the cause of the
              divergences and point out that resorting to more
              concrete, syntactic domains can be avoided by
              researching suitable algorithms for the elimination of
              redundant constraints in the chosen representation.",
  URL = "http://www.cs.unipr.it/ppl/Documentation/BagnaraHMZ04EA.pdf"
}

@InProceedings{BagnaraHZ02a,
  Author = "R. Bagnara and P. M. Hill and E. Zaffanella",
  Title = "A New Encoding of Not Necessarily Closed Convex Polyhedra",
  Booktitle = "Proceedings of the 1st CoLogNet Workshop on Component-based
               Software Development and Implementation Technology
               for Computational Logic Systems",
  Address = "Madrid, Spain",
  Editor = "M. Carro and C. Vacheret and K.-K. Lau",
  Year = 2002,
  Pages = "147--153",
  Note = "Published as TR Number CLIP4/02.0, Universidad Polit\'ecnica
          de Madrid, Facultad de Inform\'atica",
  URL = "http://www.cs.unipr.it/ppl/Documentation/BagnaraHZ02a.pdf"
}

@TechReport{BagnaraHZ02TR,
  Author = "R. Bagnara and P. M. Hill and E. Zaffanella",
  Title = "A New Encoding and Implementation
           of Not Necessarily Closed Convex Polyhedra",
  Number = 305,
  Type = "Quaderno",
  Institution = "Dipartimento di Matematica, Universit\`a di Parma, Italy",
  Year = 2002,
  Note = "Available at \url{http://www.cs.unipr.it/Publications/}",
  Abstract = "Convex polyhedra, commonly employed for the analysis and
              verification of both hardware and software, may be
              defined either by a finite set of linear inequality
              constraints or by finite sets of generating points and
              rays of the polyhedron.  Although most implementations
              of the polyhedral operations assume that the polyhedra
              are topologically closed (i.e., all the constraints
              defining them are non-strict), several analyzers and
              verifiers need to compute on a domain of convex
              polyhedra that are not necessarily closed (NNC).  The
              usual approach to implementing NNC polyhedra is to embed
              them into closed polyhedra in a vector space having one
              extra dimension and reuse the tools and techniques
              already available for closed polyhedra.  Previously,
              this embedding has been designed so that a constant
              number of constraints and a linear number of generators
              have to be added to the original NNC specification of
              the polyhedron.  In this paper we explore an alternative
              approach: while still using an extra dimension to
              represent the NNC polyhedron by a closed polyhedron, the
              new embedding adds a linear number of constraints and a
              constant number of generators.  We discuss the relative
              benefits of these two implementations and how the choice
              of representation can affect the efficiency of the
              polyhedral operations.  As far as the issue of providing
              a non-redundant description of the NNC polyhedron is
              concerned, we generalize the results established in a
              previous paper so that they apply to both encodings."
}

@Article{BagnaraHRZ05SCP,
  Author = "R. Bagnara and P. M. Hill and E. Ricci and E. Zaffanella",
  Title = "Precise Widening Operators for Convex Polyhedra",
  Journal = "Science of Computer Programming",
  Volume = 58,
  Number = "1--2",
  Year = 2005,
  Pages = "28--56",
  Abstract = "In the context of static analysis via abstract
              interpretation, convex polyhedra constitute the most
              used abstract domain among those capturing numerical
              relational information.  Since the domain of convex
              polyhedra admits infinite ascending chains, it has to be
              used in conjunction with appropriate mechanisms for
              enforcing and accelerating the convergence of fixpoint
              computations.  Widening operators provide a simple and
              general characterization for such mechanisms.  For the
              domain of convex polyhedra, the original widening
              operator proposed by Cousot and Halbwachs amply deserves
              the name of \emph{standard widening} since most analysis
              and verification tools that employ convex polyhedra also
              employ that operator.  Nonetheless, there is an
              unfulfilled demand for more precise widening operators.
              In this paper, after a formal introduction to the
              standard widening where we clarify some aspects that are
              often overlooked, we embark on the challenging task of
              improving on it.  We present a framework for the
              systematic definition of new widening operators that are
              never less precise than a given widening.  The framework
              is then instantiated on the domain of convex polyhedra
              so as to obtain a new widening operator that improves on
              the standard widening by combining several heuristics.
              A preliminary experimental evaluation has yielded
              promising results.  We also suggest an improvement to
              the well-known widening delay technique that allows to
              gain precision while preserving its overall
              simplicity.",
  URL = "http://www.cs.unipr.it/ppl/Documentation/BagnaraHRZ05SCP.pdf"
}

@TechReport{BagnaraHMZ05TR,
  Author = "R. Bagnara and P. M. Hill and E. Mazzi and E. Zaffanella",
  Title = "Widening Operators for Weakly-Relational Numeric Abstractions",
  Number = 399,
  Type = "Quaderno",
  Institution = "Dipartimento di Matematica, Universit\`a di Parma, Italy",
  Year = 2005,
  Note = "Available at \url{http://www.cs.unipr.it/Publications/}",
  Abstract = "We discuss the construction of proper widening operators
              on several weakly-relational numeric abstractions. Our
              proposal differs from previous ones in that we actually
              consider the semantic abstract domains, whose elements
              are \emph{geometric shapes}, instead of the (more
              concrete) syntactic abstract domains of constraint
              networks and matrices.  Since the closure by entailment
              operator preserves geometric shapes, but not their
              syntactic expressions, our widenings are immune from the
              divergence issues that could be faced by the previous
              approaches when interleaving the applications of
              widening and closure.  The new widenings, which are
              variations of the \emph{standard widening} for convex
              polyhedra defined by Cousot and Halbwachs, can be made
              as precise as the previous proposals working on the
              syntactic domains.  The implementation of each new
              widening relies on the availability of an effective
              reduction procedure for the considered constraint
              description: we provide such an algorithm for the domain
              of \emph{octagonal shapes}.",
  URL = "http://www.cs.unipr.it/ppl/Documentation/BagnaraHMZ05TR.pdf"
}

@InProceedings{BagnaraHMZ05,
  Author = "R. Bagnara and P. M. Hill and E. Mazzi and E. Zaffanella",
  Title = "Widening Operators for Weakly-Relational Numeric Abstractions",
  Booktitle = "Static Analysis:
               Proceedings of the 12th International Symposium",
  Address = "London, UK",
  Editor = "C. Hankin and I. Siveroni",
  Publisher = "Springer-Verlag, Berlin",
  Series = "Lecture Notes in Computer Science",
  Volume = 3672,
  ISBN = "3-540-28584-9",
  Year = 2005,
  Pages = "3--18",
  Abstract = "We discuss the construction of proper widening operators
              on several weakly-relational numeric abstractions. Our
              proposal differs from previous ones in that we actually
              consider the semantic abstract domains, whose elements are
              \emph{geometric shapes}, instead of the (more concrete)
              syntactic abstract domains of constraint networks and
              matrices. Since the closure by entailment operator preserves
              geometric shapes, but not their syntactic expressions, our
              widenings are immune from the divergence issues that could
              be faced by the previous approaches when interleaving the
              applications of widening and closure. The new widenings,
              which are variations of the \emph{standard widening} for
              convex polyhedra defined by Cousot and Halbwachs, can be
              made as precise as the previous proposals working on the
              syntactic domains. The implementation of each new widening
              relies on the availability of an effective reduction procedure
              for the considered constraint description: we provide such an
              algorithm for the domain of \emph{octagonal shapes}.",
}

@InProceedings{BagnaraRZH02,
  Author = "R. Bagnara and E. Ricci and E. Zaffanella and P. M. Hill",
  Title = "Possibly Not Closed Convex Polyhedra
           and the {Parma Polyhedra Library}",
  Booktitle = "Static Analysis:
               Proceedings of the 9th International Symposium",
  Address = "Madrid, Spain",
  Editor = "M. V. Hermenegildo and G. Puebla",
  Publisher = "Springer-Verlag, Berlin",
  Series = "Lecture Notes in Computer Science",
  Volume = 2477,
  ISBN = "3-540-44235-9",
  Pages = "213--229",
  Year = 2002,
  Abstract = "The domain of convex polyhedra is employed in several
              systems for the analysis and verification of hardware
              and software components.  Current applications span
              imperative, functional and logic languages, synchronous
              languages and synchronization protocols, real-time and
              hybrid systems.  Since the seminal work of P.~Cousot and
              N.~Halbwachs, convex polyhedra have thus played an
              important role in the formal methods community and
              several critical tasks rely on their software
              implementations.  Despite this, existing libraries for
              the manipulation of convex polyhedra are still research
              prototypes and suffer from limitations that make their
              usage problematic, especially in critical applications.
              Furthermore, there is inadequate support for polyhedra
              that are not necessarily closed (NNC), i.e., polyhedra
              that are described by systems of constraints where strict
              inequalities are allowed to occur.  This paper presents
              the Parma Polyhedra Library, a new, robust and complete
              implementation of NNC convex polyhedra, concentrating on
              the distinctive features of the library and on the novel
              theoretical underpinnings.",
  URL = "http://www.cs.unipr.it/ppl/Documentation/BagnaraRZH02.pdf"
}

@TechReport{BagnaraRZH02TR,
  Author = "R. Bagnara and E. Ricci and E. Zaffanella and P. M. Hill",
  Title = "Possibly Not Closed Convex Polyhedra
           and the {Parma Polyhedra Library}",
  Number = 286,
  Type = "Quaderno",
  Institution = "Dipartimento di Matematica, Universit\`a di Parma, Italy",
  Year = "{\noopsort{a}}2002",
  Note = "See also \cite{BagnaraRZH02TRerrata}.
          Available at \url{http://www.cs.unipr.it/Publications/}",
  Abstract = "The domain of convex polyhedra is employed in several
              systems for the analysis and verification of hardware
              and software components. Current applications span imperative,
              functional and logic languages, synchronous languages and
              synchronization protocols, real-time and hybrid systems.
              Since the seminal work of P.~Cousot and N.~Halbwachs,
              convex polyhedra have thus played an important role
              in the formal methods community and several critical tasks
              rely on their software implementations. Despite this,
              existing libraries for the manipulation of convex polyhedra
              are still research prototypes and suffer from limitations
              that make their usage problematic, especially in critical
              applications. These limitations concern inaccuracies in
              the documentation of the underlying theory, code and
              interfaces; numeric overflow and underflow; use of not
              fully dynamic data-structures and poor mechanisms
              for error handling and recovery. In addition, there is
              inadequate support for polyhedra that are not necessarily
              closed (NNC), i.e., polyhedra that are described by systems
              of constraints where strict inequalities are allowed to
              occur. This paper presents the Parma Polyhedra Library,
              a new, robust and complete implementation of NNC convex
              polyhedra, concentrating on the distinctive features
              of the library and on the novel theoretical underpinnings."
}

@Misc{BagnaraRZH02TRerrata,
  Author = "R. Bagnara and E. Ricci and E. Zaffanella and P. M. Hill",
  Title = "Errata for Technical Report {``Quaderno 286''}",
  Howpublished = "Available at \url{http://www.cs.unipr.it/Publications/}",
  Year = "{\noopsort{b}}2002",
  Note = "See \cite{BagnaraRZH02TR}"
}

@InProceedings{BagnaraHRZ03,
  Author = "R. Bagnara and P. M. Hill and E. Ricci and E. Zaffanella",
  Title = "Precise Widening Operators for Convex Polyhedra",
  Booktitle = "Static Analysis:
               Proceedings of the 10th International Symposium",
  Address = "San Diego, California, USA",
  Editor = "R. Cousot",
  Publisher = "Springer-Verlag, Berlin",
  Series = "Lecture Notes in Computer Science",
  Volume = 2694,
  Year = 2003,
  Pages = "337--354",
  Abstract = "Convex polyhedra constitute the most used abstract
              domain among those capturing numerical relational
              information.  Since the domain of convex polyhedra
              admits infinite ascending chains, it has to be used in
              conjunction with appropriate mechanisms for enforcing
              and accelerating convergence of the fixpoint
              computation.  Widening operators provide a simple and
              general characterization for such mechanisms.  For the
              domain of convex polyhedra, the original widening
              operator proposed by Cousot and Halbwachs amply deserves
              the name of \emph{standard widening} since most analysis
              and verification tools that employ convex polyhedra also
              employ that operator.  Nonetheless, there is an
              unfulfilled demand for more precise widening operators.
              In this paper, after a formal introduction to the
              standard widening where we clarify some aspects that are
              often overlooked, we embark on the challenging task of
              improving on it.  We present a framework for the
              systematic definition of new and precise widening
              operators for convex polyhedra.  The framework is then
              instantiated so as to obtain a new widening operator
              that combines several heuristics and uses the standard
              widening as a last resort so that it is never less
              precise.  A preliminary experimental evaluation has
              yielded promising results.",
  URL = "http://www.cs.unipr.it/ppl/Documentation/BagnaraHRZ03.pdf"
}

@TechReport{BagnaraHRZ03TR,
  Author = "R. Bagnara and P. M. Hill and E. Ricci and E. Zaffanella",
  Title = "Precise Widening Operators for Convex Polyhedra",
  Number = 312,
  Type = "Quaderno",
  Institution = "Dipartimento di Matematica, Universit\`a di Parma, Italy",
  Year = 2003,
  Note = "Available at \url{http://www.cs.unipr.it/Publications/}",
  Abstract = "Convex polyhedra constitute the most used abstract
              domain among those capturing numerical relational
              information.  Since the domain of convex polyhedra
              admits infinite ascending chains, it has to be used in
              conjunction with appropriate mechanisms for enforcing
              and accelerating convergence of the fixpoint
              computation.  Widening operators provide a simple and
              general characterization for such mechanisms.  For the
              domain of convex polyhedra, the original widening
              operator proposed by Cousot and Halbwachs amply deserves
              the name of \emph{standard widening} since most analysis
              and verification tools that employ convex polyhedra also
              employ that operator.  Nonetheless, there is demand for
              more precise widening operators that still has not been
              fulfilled.  In this paper, after a formal introduction
              to the standard widening where we clarify some aspects
              that are often overlooked, we embark on the challenging
              task of improving on it.  We present a framework for the
              systematic definition of new and precise widening
              operators for convex polyhedra.  The framework is then
              instantiated so as to obtain a new widening operator
              that combines several heuristics and uses the standard
              widening as a last resort so that it is never less
              precise.  A preliminary experimental evaluation has
              yielded promising results.  We also suggest an
              improvement to the well-known widening delay technique
              that allows to gain precision while preserving its
              overall simplicity."
}

@InProceedings{BagnaraHZ03a,
  Author = "R. Bagnara and P. M. Hill and E. Zaffanella",
  Title = "A New Encoding and Implementation
           of Not Necessarily Closed Convex Polyhedra",
  Booktitle = "Proceedings of the 3rd Workshop on Automated Verification
               of Critical Systems",
  Address = "Southampton, UK",
  Editor = "M. Leuschel and S. Gruner and S. {Lo Presti}",
  Year = 2003,
  Pages = "161--176",
  Note = "Published as TR Number DSSE-TR-2003-2, University of Southampton",
  Abstract = "Convex polyhedra, commonly employed for the analysis and
              verification of both hardware and software, may be
              defined either by a finite set of linear inequality
              constraints or by finite sets of generating points and
              rays of the polyhedron.  Although most implementations
              of the polyhedral operations assume that the polyhedra
              are topologically closed (i.e., all the constraints
              defining them are non-strict), several analyzers and
              verifiers need to compute on a domain of convex
              polyhedra that are not necessarily closed (NNC).  The
              usual approach to implementing NNC polyhedra is to embed
              them into closed polyhedra in a vector space having one
              extra dimension and reuse the tools and techniques
              already available for closed polyhedra.  Previously,
              this embedding has been designed so that a constant
              number of constraints and a linear number of generators
              have to be added to the original NNC specification of
              the polyhedron.  In this paper we explore an alternative
              approach: while still using an extra dimension to
              represent the NNC polyhedron by a closed polyhedron, the
              new embedding adds a linear number of constraints and a
              constant number of generators.  We discuss the relative
              benefits of these two implementations and how the choice
              of representation can affect the efficiency of the
              polyhedral operations.  As far as the issue of providing
              a non-redundant description of the NNC polyhedron is
              concerned, we generalize the results established in a
              previous paper so that they apply to both encodings.",
  URL = "http://www.cs.unipr.it/ppl/Documentation/BagnaraHZ03a.pdf"
}

@InProceedings{BagnaraHZ03b,
  Author = "R. Bagnara and P. M. Hill and E. Zaffanella",
  Title = "Widening Operators for Powerset Domains",
  Booktitle = "Verification, Model Checking and Abstract Interpretation:
               Proceedings of the 5th International Conference (VMCAI 2004)",
  Address = "Venice, Italy",
  Editor = "B. Steffen and G. Levi",
  Publisher = "Springer-Verlag, Berlin",
  Series = "Lecture Notes in Computer Science",
  Volume = 2937,
  ISBN = "3-540-20803-8",
  Year = 2003,
  Pages = "135--148",
  Abstract = "The \emph{finite powerset construction} upgrades an
              abstract domain by allowing for the representation of
              finite disjunctions of its elements.  In this paper we
              define two generic widening operators for the finite
              powerset abstract domain.  Both widenings are obtained
              by lifting any widening operator defined on the
              base-level abstract domain and are parametric with
              respect to the specification of a few additional
              operators.  We illustrate the proposed techniques by
              instantiating our widenings on powersets of convex
              polyhedra, a domain for which no non-trivial widening
              operator was previously known.",
  URL = "http://www.cs.unipr.it/ppl/Documentation/BagnaraHZ03b.pdf"
}

@TechReport{BagnaraHZ04TR,
  Author = "R. Bagnara and P. M. Hill and E. Zaffanella",
  Title = "Widening Operators for Powerset Domains",
  Number = 349,
  Type = "Quaderno",
  Institution = "Dipartimento di Matematica, Universit\`a di Parma, Italy",
  Year = 2004,
  Note = "Available at \url{http://www.cs.unipr.it/Publications/}",
  Abstract = "The \emph{finite powerset construction} upgrades an
              abstract domain by allowing for the representation of
              finite disjunctions of its elements.  In this paper we
              define two generic widening operators for the finite
              powerset abstract domain.  Both widenings are obtained
              by lifting any widening operator defined on the
              base-level abstract domain and are parametric with
              respect to the specification of a few additional
              operators.  We illustrate the proposed techniques by
              instantiating our widenings on powersets of convex
              polyhedra, a domain for which no non-trivial widening
              operator was previously known.",
}

@Article{BagnaraHZ05FAC,
  Author = "R. Bagnara and P. M. Hill and E. Zaffanella",
  Title = "Not Necessarily Closed Convex Polyhedra
           and the Double Description Method",
  Journal = "Formal Aspects of Computing",
  Publisher = "Springer-Verlag, London",
  Volume = "17",
  Number = "2",
  Pages = "222--257",
  Year = 2005,
  ISSN = "0934-5043",
  Abstract = "Since the seminal work of Cousot and Halbwachs, the domain
              of convex polyhedra has been employed in several systems
              for the analysis and verification of hardware and software
              components. Although most implementations of the polyhedral
              operations assume that the polyhedra are topologically
              closed (i.e., all the constraints defining them are
              non-strict), several analyzers and verifiers need to
              compute on a domain of convex polyhedra that are not
              necessarily closed (NNC). The usual approach to
              implementing NNC polyhedra is to embed them into closed
              polyhedra in a higher dimensional vector space and reuse
              the tools and techniques already available for closed
              polyhedra. In this work we highlight and discuss the issues
              underlying such an embedding for those implementations that
              are based on the \emph{double description} method, where a
              polyhedron may be described by a system of linear
              constraints or by a system of generating rays and points.
              Two major achievements are the definition of a
              theoretically clean, high-level user interface and the
              specification of an efficient procedure for removing
              redundancies from the descriptions of NNC polyhedra.",
}

@Article{BagnaraHZ06STTT,
  Author = "R. Bagnara and P. M. Hill and E. Zaffanella",
  Title = "Widening Operators for Powerset Domains",
  Journal = "Software Tools for Technology Transfer",
  Publisher = "Springer-Verlag, Berlin",
  Year = 2006,
  Note = "To appear",
}

@TechReport{BagnaraHZ06TR,
  Author = "R. Bagnara and P. M. Hill and E. Zaffanella",
  Title = "The {Parma Polyhedra Library}: Toward a Complete Set of Numerical
           Abstractions for the Analysis and Verification
           of Hardware and Software Systems",
  Number = 457,
  Type = "Quaderno",
  Institution = "Dipartimento di Matematica, Universit\`a di Parma, Italy",
  Year = 2006,
  Note = "Available at \url{http://www.cs.unipr.it/Publications/}.
          Also published as {\tt arXiv:cs.MS/0612085},
          available from \url{http://arxiv.org/}."
  Abstract = "Since its inception as a student project in 2001,
              initially just for the handling (as the name implies) of
              convex polyhedra, the \emph{Parma Polyhedra Library} has
              been continuously improved and extended by joining
              scrupulous research on the theoretical foundations of
              (possibly non-convex) numerical abstractions to a total
              adherence to the best available practices in software
              development.  Even though it is still not fully mature
              and functionally complete, the Parma Polyhedra Library
              already offers a combination of functionality,
              reliability, usability and performance that is not
              matched by similar, freely available libraries.  In this
              paper, we present the main features of the current
              version of the library, emphasizing those that
              distinguish it from other similar libraries and those
              that are important for applications in the field of
              analysis and verification of hardware and software
              systems.",
}

@InProceedings{BalasundaramK89,
  Author = "V. Balasundaram and K. Kennedy",
  Title = "A Technique for Summarizing Data Access
           and Its Use in Parallelism Enhancing Transformations",
  Booktitle = "Proceedings of the ACM SIGPLAN'89 Conference
               on Programming Language Design and Implementation (PLDI)",
  Address = "Portland, Oregon, USA",
  Editor = "B. Knobe",
  Series = "ACM SIGPLAN Notices",
  Volume = "24(7)",
  Publisher = "ACM Press",
  Year = 1989,
  Pages = "41--53",
}

@InProceedings{BessonJT99,
  Author = "F. Besson and T. P. Jensen and J.-P. Talpin",
  Title = "Polyhedral Analysis for Synchronous Languages",
  Booktitle = "Static Analysis:
               Proceedings of the 6th International Symposium",
  Address = "Venice, Italy",
  Editor = "A. Cortesi and G. Fil\'e",
  Publisher = "Springer-Verlag, Berlin",
  Series = "Lecture Notes in Computer Science",
  Volume = 1694,
  ISBN = "3-540-66459-9",
  Year = 1999,
  Pages = "51--68",
  Abstract = "We define an operational semantics for the \textsc{Signal}
              language and design an analysis which allows to verify
              properties pertaining to the relation between values of
              the numeric and boolean variables of a reactive
              system. A distinguished feature of the analysis is that
              it is expressed and proved correct with respect to the
              source program rather than on an intermediate
              representation of the program. The analysis calculates a
              safe approximation to the set of reachable states by a
              symbolic fixed point computation in the domain of convex
              polyhedra using a novel widening operator based on the
              convex hull representation of polyhedra."
}

@Article{BultanGP99,
  Author = "T. Bultan and R. Gerber and W. Pugh",
  Title = "Model-Checking Concurrent Systems with Unbounded Integer
           Variables: Symbolic Representations, Approximations, and
           Experimental Results",
  Journal = "ACM Transactions on Programming Languages and Systems",
  Volume = 21,
  Number = 4,
  Publisher = "ACM Press",
  Year = 1999,
  ISSN = "0164-0925",
  Pages = "747--789",
  Abstract = "Model checking is a powerful technique for analyzing
              large, finite-state systems. In an infinite state
              system, however, many basic properties are
              undecidable. In this article, we present a new symbolic
              model checker which conservatively evaluates safety and
              liveness properties on programs with unbounded integer
              variables. We use Presburger formulas to symbolically
              encode a program's transition system, as well as its
              model-checking computations. All fixpoint calculations
              are executed symbolically, and their convergence is
              guaranteed by using approximation techniques. We
              demonstrate the promise of this technology on some
              well-known infinite-state concurrency problems.",
  URL = "http://www.cs.ucsb.edu/~bultan/publications/toplas.ps"
}

@Article{Chernikova64,
  Author = "N. V. Chernikova",
  Title = "Algorithm for Finding a General Formula for the Non-Negative
           Solutions of System of Linear Equations",
  Journal = "U.S.S.R. Computational Mathematics and Mathematical Physics",
  Publisher = "MAIK NAUKA/Interperiodica Publishing, Moscow",
  Volume = 4,
  Number = 4,
  Pages = "151--158",
  Year = 1964
}

@Article{Chernikova65,
  Author = "N. V. Chernikova",
  Title = "Algorithm for Finding a General Formula for the Non-Negative
           Solutions of System of Linear Inequalities",
  Journal = "U.S.S.R. Computational Mathematics and Mathematical Physics",
  Publisher = "MAIK NAUKA/Interperiodica Publishing, Moscow",
  Volume = 5,
  Number = 2,
  Pages = "228--233",
  Year = 1965,
  Abstract = "The present note proposes a computational scheme
              for finding a general formula for the non-negative
              solutions of a system of linear inequalities
              analogous to the scheme described in \cite{Chernikova64}
              for finding a general formula for the non-negative
              solutions of a system of linear equations."
}

@Article{Chernikova68,
  Author = "N. V. Chernikova",
  Title = "Algorithm for Discovering the Set of all Solutions
           of a Linear Programming Problem",
  Journal = "U.S.S.R. Computational Mathematics and Mathematical Physics",
  Publisher = "MAIK NAUKA/Interperiodica Publishing, Moscow",
  Volume = 8,
  Number = 6,
  Pages = "282--293",
  Year = 1968,
  Abstract = "In this paper two versions of a canonical algorithm for
              discovering all the optimal solutions of a linear
              programming problem with the condition of non-negativeness
              of the variables are presented: the first for the case
              of canonical notation, the second for the standard notation."
}

@InProceedings{CousotC76,
  Author = "P. Cousot and R. Cousot",
  Title = "Static Determination of Dynamic Properties of Programs",
  Booktitle = "Proceedings of the Second International
               Symposium on Programming",
  Editor = "B. Robinet",
  Address = "Paris, France",
  Publisher = "Dunod, Paris, France",
  Pages = "106--130",
  Year = 1976,
  Abstract = "In high level languages, compile time type verifications are
              usually incomplete, and dynamic coherence checks must be
              inserted in object code. For example, in PASCAL one must
              dynamically verify that the values assigned to subrange type
              variables, or index expressions lie between two bounds, or
              that pointers are not \texttt{nil}, ...
              We present here a general algorithm allowing most of these
              certifications to be done at compile time.",
  URL = "http://www.di.ens.fr/~cousot/publications.www/CousotCousot-ISOP-76-Dunod-p106--130-1976.pdf"
}

@InProceedings{CousotC79,
  Author = "P. Cousot and R. Cousot",
  Title = "Systematic Design of Program Analysis Frameworks",
  Booktitle = "Proceedings of the Sixth Annual ACM
               Symposium on Principles of Programming Languages",
  Publisher = "ACM Press",
  Address = "New York",
  Pages = "269--282",
  Year = 1979,
  Abstract = "Semantic analysis of programs is essential in optimizing
              compilers and program verification systems. It encompasses
              data flow analysis, data type determination, generation of
              approximate invariant assertions, etc.
              Several recent papers (among others Cousot \& Cousot[77a],
              Graham & Wegman[76], Kam & Ullmann[76], Killdall[73],
              Rosen[78], Tarjan[76], Wegbreit[75]) have introduced abstract
              approaches to program analysis which are tantamount to the
              use of a \emph{program analysis framework} $(A, t, \gamma)$
              where $A$ is a lattice of (approximate) assertions,
              $t$ is an (approximate) predicate transformer and
              $\gamma$ is an often implicit function specifying the
              meaning of the elements of $A$. This paper is devoted to
              the systematic and correct design of program analysis
              frameworks with respect to a formal semantics.",
  URL = "http://www.di.ens.fr/~cousot/publications.www/CousotCousot-POPL-79-ACM-p269--282-1979.pdf"
}

@InProceedings{CousotC92-PLILP,
  Author = "P. Cousot and R. Cousot",
  Title =  "Comparing the {Galois} Connection and Widening/Narrowing
            Approaches to Abstract Interpretation",
  Booktitle = "Proceedings of the 4th International Symposium
               on Programming Language Implementation and Logic Programming",
  Address = "Leuven, Belgium",
  Editor = "M. Bruynooghe and M. Wirsing",
  Publisher = "Springer-Verlag, Berlin",
  Series = "Lecture Notes in Computer Science",
  Volume = 631,
  ISBN = "3-540-55844-6",
  Pages = "269--295",
  Year = 1992,
  Abstract = "The use of infinite abstract domains with widening and
              narrowing for accelerating the convergence of abstract
              interpretations is shown to be more powerful than the Galois
              connection approach restricted to finite lattices (or lattices
              satisfying the chain condition).",
  URL = "http://www.di.ens.fr/~cousot/publications.www/CousotCousot-PLILP-92-LNCS-n631-p269--295-1992.pdf"
}

@InProceedings{CousotH78,
  Author = "P. Cousot and N. Halbwachs",
  Title = "Automatic Discovery of Linear Restraints Among
           Variables of a Program",
  Booktitle = "Conference Record of the Fifth Annual ACM
              Symposium on Principles of Programming Languages",
  Address = "Tucson, Arizona",
  Publisher = "ACM Press",
  Pages = "84--96",
  Year = 1978,
  Abstract = "The model of abstract interpretation of programs developed
              by Cousot & Cousot [1976] and Cousot & Cousot [1977]
              is applied to the static determination of linear equality
              or inequality relations among variables of programs.",
  URL = "http://www.di.ens.fr/~cousot/publications.www/CousotHalbwachs-POPL-78-ACM-p84--97-1978.pdf"
}

@Book{Dantzig63,
  Author = "G. B. Dantzig",
  Title = "Linear Programming and Extensions",
  Publisher = "Princeton University Press",
  Address = "Princeton, NJ",
  Year = 1963
}

@Misc{Fukuda98,
  Author = "K. Fukuda",
  Title = "Polyhedral Computation {FAQ}",
  Howpublished = "Swiss Federal Institute of Technology,
                 Lausanne and Zurich, Switzerland,
                 available at
                 \url{http://www.ifor.math.ethz.ch/~fukuda/polyfaq/polyfaq.html}",
  Year = 1998,
  Abstract = "This is an FAQ to answer some basic questions arising
              from certain geometric computation in general dimensional
              (mostly Euclidean) space. The main areas to be covered are
              the convex hull computation of a finite point set, the
              vertex enumeration for a convex polytope, the computation
              of Voronoi diagram and Delaunay triangulation, in $R^d$.
              We illustrate typical solution processes with small examples
              and publicly available codes such as cdd+ and lrs.",
}

@InProceedings{FukudaP96,
  Author = "K. Fukuda and A. Prodon",
  Title = "Double Description Method Revisited",
  Booktitle = "Combinatorics and Computer Science,
               8th Franco-Japanese and 4th Franco-Chinese Conference,
               Brest, France, July 3-5, 1995, Selected Papers",
  Editor = "M. Deza and R. Euler and Y. Manoussakis",
  Publisher = "Springer-Verlag, Berlin",
  Series = "Lecture Notes in Computer Science",
  Volume = 1120,
  Pages = "91--111",
  Year = 1996,
  ISBN = "3-540-61576-8",
  Abstract = "The double description method is a simple and useful
              algorithm for enumerating all extreme rays of a general
              polyhedral cone in $R^d$, despite the fact that
              we can hardly state any interesting theorems on its time
              and space complexities.  In this paper, we reinvestigate
              this method, introduce some new ideas for efficient
              implementations, and show some empirical results indicating
              its practicality in solving highly degenerate problems.",
  URL = "ftp://ftp.ifor.math.ethz.ch/pub/fukuda/reports/ddrev960315.ps.gz"
}

@InCollection{GawrilowJ00,
  Author = "E. Gawrilow and M. Joswig",
  Title =  "{\tt polymake}: A Framework for Analyzing Convex Polytopes",
  Booktitle = "Polytopes - Combinatorics and Computation",
  Editor = "G. Kalai and G. M. Ziegler",
  Publisher = "Birkh{\"a}user",
  Pages =  "43--74",
  Year = 2000,
  Abstract = "{\tt polymake} is a software tool designed for the algorithmic
              treatment of polytopes and polyhedra. We give an overview of the
              functionally as well as for the structure. This paper can be seen
              as a first approximation to a {\tt polymake} handbook.
              The tutorial starts with the very basic and ends with a few
              {\tt polymake} applications to research problems. Then we
              present the main features of the system including the interfaces
              to other software products."
}

@InProceedings{GawrilowJ01,
  Author = "E. Gawrilow and M. Joswig",
  Title = "{\tt polymake}: An Approach to Modular Software Design in
           Computational Geometry",
  Booktitle = "Proceedings of the 17th Annual Symposium on Computational
               Geometry",
  Organization = "ACM",
  Address = "Medford, MA, USA",
  Pages = "222--231",
  Year = 2001,
  Abstract = "{\tt polymake} is a software package designed for the study of
              the combinatorics and the geometry of convex polytopes and
              polyhedra. It offers access to a wide variety of algorithms and
              tools within a common framework. As a key design feature it
              allows to incorporate the functionality of a great variety of
              other software packages in a modular way."
}

@InProceedings{GopanDMDRS04,
  Author = "D. Gopan and  F. DiMaio and N. Dor and T. Reps and M. Sagiv",
  Title = "Numeric Domains with Summarized Dimensions",
  Booktitle = "Tools and Algorithms for the Construction and Analysis
               of Systems, 10th International Conference, TACAS 2004",
  Address = "Barcelona, Spain",
  Editor = "K. Jensen and A. Podelski",
  Publisher = "Springer-Verlag, Berlin",
  Series = "Lecture Notes in Computer Science",
  Volume = 2988,
  Pages = "512--529",
  Year = 2004,
  ISBN = "3-540-21299-X",
  Abstract = "We introduce a systematic approach to designing
              summarizing abstract numeric domains from existing
              numeric domains. Summarizing domains use summary
              dimensions to represent potentially unbounded
              collections of numeric objects. Such domains are of
              benefit to analyses that verify properties of systems
              with an unbounded number of numeric objects, such as
              shape analysis, or systems in which the number of
              numeric objects is bounded, but large."
}

@InProceedings{Granger91,
  Author = "P. Granger",
  Title = "Static Analysis of Linear Congruence Equalities
           among Variables of a Program",
  Booktitle = "TAPSOFT'91: Proceedings of the International Joint Conference
               on Theory and Practice of Software Development,
               Volume 1: Colloquium on Trees in Algebra and Programming
               (CAAP'91)",
  Address = "Brighton, UK",
  Year = 1991,
  Editor = "S. Abramsky and T. S. E. Maibaum",
  Publisher = "Springer-Verlag, Berlin",
  Series = "Lecture Notes in Computer Science",
  Volume = 493,
  ISBN = "3-540-53982-4",
  Pages = "169--192",
  Abstract = "In this paper, a new kind of static (or semantic)
             analysis is defined: congruence analysis, which is
             conceived to discover the properties of the following
             type: ``the integer valued variable $X$ is congruent to
             $c$ modulo $m$'', where $c$ and $m$ are automatically
             determined integers. This analysis is then related to an
             algebraic framework and wholly characterized. Moreover,
             we show an example how it can be useful for automatic
             vectorization. Finally, we present some extensions of it,
             namely its combination with the analysis of bounds, and
             also some analysis defined when the modulus of
             congruences is given \emph{a priori}.",
}

@InProceedings{Granger97,
  Author = "P. Granger",
  Title = "Static Analyses of Congruence Properties on Rational Numbers
           (Extended Abstract)",
  Booktitle = "Static Analysis: Proceedings of the 4th International
               Symposium",
  Address = "Paris, France",
  Year = 1997,
  Editor = "P. {Van Hentenryck}",
  Publisher = "Springer-Verlag, Berlin",
  Series = "Lecture Notes in Computer Science",
  Volume = 1302,
  ISBN = "3-540-63468-1",
  Pages = "278--292",
  Abstract = "We present several new static analysis frameworks
             applying to rational numbers, and more precisely,
             designed for discovering congruence properties satisfied
             by rational (or real) variables of programs. Two of them
             deal with additive congruence properties and generalize
             linear equation analysis [M. Karr, \emph{Affine
             Relationships among Variables of a Program}, Acta
             Informatica, 6:133--151, 1976] and congruence analysis on
             integer numbers [P. Granger, \emph{Static Analysis of
             Arithmetical Congruences}, International Journal of
             Computer Mathematics, 30:165--190, 1989], [P. Granger,
             \emph{Static Analysis of Linear Congruence Equalities
             among Variables of a Program}, TAPSOFT'91: Proceedings of
             the International Joint Conference on Theory and Practice
             of Software Development, Volume 1: Colloquium on Trees in
             Algebra and Programming (CAAP'91), Lecture Notes in
             Computer Science, 493, pp. 169--192].  The others are
             based on multiplicative congruence properties in the set
             of positive rational numbers. Among other potential
             applications, we exemplify the interest of all these
             analyses for optimizing the representation of rational or
             real valued variables."
}

@Article{GoldfarbR77,
  Author = "D. Goldfarb and J. K. Reid",
  Title = "A Practical Steepest-Edge Simplex Algorithm",
  Journal = "Mathematical Proramming",
  Volume = 12,
  Number = 1,
  Pages = "361--371",
  Year = 1977,
  Abstract = "It is shown that suitable recurrences may be used in
              order to implement in practice the steepest-edge simplex
              linear programming algorithm. In this algorithm each
              iteration is along an edge of the polytope of feasible
              solutions on which the objective function decreases most
              rapidly with respect to distance in the space of all the
              variables. Results of computer comparisons on
              medium-scale problems indicate that the resulting
              algorithm requires less iterations but about the same
              overall time as the algorithm of Harris [8], which may
              be regarded as approximating the steepest-edge
              algorithm. Both show a worthwhile advantage over the
              standard algorithm."
}

@PhdThesis{Halbwachs79th,
  Author = "N. Halbwachs",
  Title = "D\'etermination Automatique de Relations Lin\'eaires
           V\'erifi\'ees par les Variables d'un Programme",
  Type = "{Th\`ese de 3\textsuperscript{\`eme} cycle d'informatique}",
  School = "Universit\'e scientifique et m\'edicale de Grenoble",
  Address = "Grenoble, France",
  Month = mar,
  Year = 1979
}

@InProceedings{Halbwachs93,
  Author = "N. Halbwachs",
  Title = "Delay Analysis in Synchronous Programs",
  Pages = "333--346",
  Booktitle = "Computer Aided Verification:
               Proceedings of the 5th International Conference",
  Address = "Elounda, Greece",
  Editor = "C. Courcoubetis",
  Publisher = "Springer-Verlag, Berlin",
  Series = "Lecture Notes in Computer Science",
  Volume = 697,
  Year = 1993,
  ISBN = "3-540-56922-7",
  Abstract = "Linear relation analysis [CH78, Hal79] has been proposed
              a long time ago as an abstract interpretation which
              permits to discover linear relations invariantly
              satisfied by the variables of a program. Here, we
              propose to apply this general method to variables used
              to count delays in synchronous programs. The ``regular''
              behavior of these counters makes the results of the
              analysis especially precise. These results can be
              applied to code optimization and to the verification of
              real-time properties of programs.",
}

@InProceedings{HalbwachsPR94,
  Author = "N. Halbwachs and Y.-E. Proy and P. Raymond",
  Title = "Verification of Linear Hybrid Systems
           by Means of Convex Approximations",
  Booktitle = "Static Analysis:
               Proceedings of the 1st International Symposium",
  Address = "Namur, Belgium",
  Editor = "B. {Le Charlier}",
  Publisher = "Springer-Verlag, Berlin",
  Series = "Lecture Notes in Computer Science",
  Volume = 864,
  ISBN = "3-540-58485-4",
  Pages = "223--237",
  Year = 1994,
  Abstract = "We present a new application of the abstract interpretation
              by means of convex polyhedra, to a class of hybrid systems,
              i.e., systems involving both discrete and continuous variables.
              The result is an efficient automatic tool for approximate,
              but conservative, verification of reachability properties
              of these systems.",
  URL = "http://www-verimag.imag.fr/PEOPLE/Nicolas.Halbwachs/hybrid.html"
}

@Manual{HalbwachsKP95,
  Author = "N. Halbwachs and A. Kerbrat and Y.-E. Proy",
  Title = "{POLyhedra INtegrated Environment}",
  Organization = "Verimag",
  Address = "France",
  Edition = "version 1.0 of {POLINE}",
  Month = sep,
  Year = 1995,
  Note = "Documentation taken from source code",
}

@Article{HalbwachsPR97,
  Author = "N. Halbwachs and Y.-E. Proy and P. Roumanoff",
  Title = "Verification of Real-Time Systems using
           Linear Relation Analysis",
  Journal = "Formal Methods in System Design",
  Publisher = "Kluwer Academic Publishers",
  Volume = 11,
  Number = 2,
  Pages = "157--185",
  Year = 1997,
  Abstract = "Linear Relation Analysis [11] is an abstract interpretation
              devoted to the automatic discovery of invariant linear
              inequalities among numerical variables of a program. In this
              paper, we apply such an analysis to the verification of
              quantitative time properties of two kinds of systems:
              synchronous programs and linear hybrid systems.",
}

@InProceedings{HenzingerH95,
  Author = "T. A. Henzinger and P.-H. Ho",
  Title = "A Note on Abstract Interpretation Strategies for Hybrid Automata",
  Booktitle = "Hybrid Systems II",
  Editor = "P. J. Antsaklis and W. Kohn and A. Nerode and S. Sastry",
  Publisher = "Springer-Verlag, Berlin",
  Series = "Lecture Notes in Computer Science",
  Volume = 999,
  Pages = "252--264",
  Year = 1995,
  Abstract = "We report on several abstract interpretation strategies
              that are designed to improve the performance of {\sc
              HyTech}, a symbolic model checker for linear hybrid
              systems. We (1) simultaneously compute the target region
              from different directions, (2) conservatively
              approximate the target region by dropping constraints,
              and (3) iteratively refine the approximation until
              sufficient precision is obtained. We consider the
              standard abstract convex-hull operator and a novel
              abstract extrapolation operator.",
  URL = "http://www-cad.eecs.berkeley.edu/HomePages/tah/Publications/abstract-interpretation_strategies_for_hybrid_automata.html"
}

@InProceedings{HenzingerPW01,
  Author = "T. A. Henzinger and J. Preussig and H. Wong-Toi",
  Title = "Some Lessons from the {\sc HyTech} Experience",
  Booktitle = "Proceedings of the 40th Annual Conference
               on Decision and Control",
  Publisher = "IEEE Computer Society Press",
  Pages = "2887--2892",
  Year = 2001,
  Abstract = "We provide an overview of the current status of the tool
              {\sc HyTech}, and reflect on some of the lessons learned
              from our experiences with the tool. HyTech is a symbolic
              model checker for mixed discrete-continuous systems that
              are modeled as automata with piecewise-constant
              polyhedral differential inclusions. The use of a formal
              input language and automated procedures for state-space
              traversal lay the foundation for formally verifying
              properties of hybrid dynamical systems. We describe some
              recent experiences analyzing three hybrid systems. We
              point out the successes and limitations of the tool. The
              analysis procedure has been extended in a number of ways
              to address some of the tool's shortcomings. We evaluate
              these extensions, and conclude with some desiderata for
              verification tools for hybrid systems.",
  URL = "http://www-cad.eecs.berkeley.edu/HomePages/tah/Publications/some_lessons_from_the_hytech_experience.html"
}

@TechReport{HuelsbergenHL90,
  Author = "L. Huelsbergen and D. Hahn and J. Larus",
  Title = "Exact Dependence Analysis Using Data Access Descriptors",
  Number = 945,
  Institution = "Department of Computer Science, University of Wisconsin",
  Address = "Madison",
  Year = 1990,
  Abstract = "\emph{Data Access Descriptors} provide a method for
              summarizing and representing the portion of an array
              accessed by a program statement. A Data Access
              Descriptor does not, however, indicate if its
              characterization is exact or conservative, nor does it
              record the temporal order of accesses. Exactness is
              necessary to expose maximal parallelism. Temporal
              information is necessary to calculate \emph{direction
              vectors} for inter-loop dependences.
              This paper presents an extension to basic Data Access
              Descriptors that identies exact representations. We
              illustrate the value of extended Data Access Descriptors
              by showing how to calculate information typically
              provided by direction vectors and by refining potential
              conflicts between statements with \emph{array kill}
              information."
}

@InProceedings{JaffarMSY94,
  Author = "J. Jaffar and M. J. Maher and P. J. Stuckey and R. H. C. Yap",
  Title = "Beyond Finite Domains",
  Booktitle = "Principles and Practice of Constraint Programming:
               Proceedings of the Second International Workshop",
  Publisher = "Springer-Verlag, Berlin",
  Editor = "A. Borning",
  Address = "Rosario, Orcas Island, Washington, USA",
  Series = "Lecture Notes in Computer Science",
  Volume = 874,
  Pages = "86--94",
  Year = 1994,
}

@Article{KhachiyanBBEG06,
  Author = "L. Khachiyan and E. Boros and K. Borys
            and K. Elbassioni and V. Gurvich",
  Title = "Generating All Vertices of a Polyhedron Is Hard",
  Journal = "Discrete and Computational Geometry",
  Publisher = "Springer",
  Address = "New York",
  Year = 2006,
  Note = "Invited contribution.  To appear.",
  Abstract = "We show that generating all negative cycles of a
              weighted graph is a hard enumeration problem, in both
              the directed and undirected cases. More precisely, given
              a family of such cycles, it is NP-complete problem to
              decide whether this family can be extended or there is
              no other negative directed cycles in the graph, implying
              that directed negative cycles cannot be generated in
              polynomial output time, unless P=NP. As a corollary, we
              solve in the negative two well-known generating problems
              from linear programming: (i) Given an (infeasible)
              system of linear inequalities, generating all minimal
              infeasible subsystems is hard. Yet, for generating
              maximal feasible subsystems the complexity remains
              open. (ii) Given a (feasible) system of linear
              inequalities, generating all vertices of the
              corresponding polyhedron is hard. Yet, in case of
              bounded polyhedra the complexity remains open."
}

@Inproceedings{NakanishiJPF99,
  Author = "T. Nakanishi and K. Joe and C. D. Polychronopoulos and A. Fukuda",
  Title = "The Modulo Interval: A Simple and Practical Representation
           for Program Analysis",
  Booktitle = "Proceedings of the 1999 International Conference on
               Parallel Architectures and Compilation Techniques",
  Address = "Newport Beach, California, USA",
  Publisher = "IEEE Computer Society",
  Year = 1999,
  Pages = "91--96",
  Abstract = "In this paper, the modulo interval, an extension of the
              traditional interval on real numbers, and its useful
              mathematical properties are presented as a
              representation for program analysis Only with two
              additional parameters to the interval on real numbers,
              namely the modulus and the residue, the modulo interval
              can represent information on program having cyclicity
              such as loop indices, array subscripts etc. at
              reasonable complexity and more accuracy. Well-defined
              arithmetic and set operations on the modulo interval
              make implementation of compilers simple and
              reliable. Moreover, application of the modulo interval
              to program analysis for parallelizing compilers is
              discussed in this paper."
}

@Article{NakanishiF01,
  Author = "T. Nakanishi and A. Fukuda",
  Title = "Modulo Interval Arithmetic and Its Application to Program Analysis",
  Journal = "Transactions of Information Processing Society of Japan",
  Volume = 42,
  Number = 4,
  Pages = "829--837",
  Year = 2001,
}

@Manual{NEW-POLKA-1-1-3c,
  Author = "B. Jeannet",
  Title = "Convex Polyhedra Library",
  Edition = "release 1.1.3c",
  Month = mar,
  Year = 2002,
  Note = "Documentation of the ``New Polka'' library available at
          \url{http://www.irisa.fr/prive/Bertrand.Jeannet/newpolka.html}",
}

@Article{Kuhn56,
  Author = "H. W. Kuhn",
  Title = "Solvability and Consistency for Linear Equations and Inequalities",
  Journal = "American Mathematical Monthly",
  Volume = 63,
  Pages = "217--232",
  Year = 1956,
}

@TechReport{LeVerge92,
  Author = "H. {Le Verge}",
  Title = "A note on {Chernikova's} Algorithm",
  Type = "\emph{Publication interne}",
  Number = 635,
  Institution = "IRISA",
  Address = "Campus de Beaulieu, Rennes, France",
  Year = 1992,
  Abstract = "This paper describes an implementation of Chernikova's
              algorithm for finding an irredundant set of vertices for a
              given polyhedron defined by a set of linear inequalities and
              equations. This algorithm can also be used for the dual
              problem: given a set of extremal rays and vertices, find the
              associated irredundant set of facet supporting hyperplanes.
              The method is an extension of initial Chernikova's
              algorithm (non negative domain), and is mainly based on the
              polyhedral cone duality principle. A new enhancement for
              extremal ray detection together with its effects on a class
              of polyhedra.",
  Source = "chernikova.c"
}

@TechReport{LeVergeVDW94,
  Author = "H. {Le Verge}, V. {Van Dongen} and D. K. Wilde",
  Title = "Loop Nest Synthesis Using the Polyhedral Library",
  Type = "\emph{Publication interne}",
  Number = 830,
  Institution = "IRISA",
  Address = "Campus de Beaulieu, Rennes, France",
  Year = 1994,
  Abstract = "A new method to synthesis loop nests given a polyhedral
              domain, the context domain, and the loop nesting order is
              described.  The method is based on functions in the IRISA
              polyhedral library."
}

@Article{LoechnerW97,
  Author = "V. Loechner and D. K. Wilde",
  Title = "Parameterized Polyhedra and Their Vertices",
  Journal = "International Journal of Parallel Programming",
  Volume = 25,
  Number = 6,
  Pages = "525--549",
  Year = 1997,
  Abstract = "Algorithms specified for parametrically sized problems are more
              general purpose and more reusable than algorithms for fixed sized
              problems. For this reason, there is a need for representing and
              symbolically analyzing linearly parameterized algorithms.
              An important class of parallel algorithms can be described as
              systems of parameterized affine recurrence equations (PARE).
              In this representation, linearly parameterized polyhedra are
              used to described the domains of variables. This paper describes
              an algorithm which computes the set of parameterized vertices of
              a polyhedron, given its representation as a system of
              parameterized inequalities. This provides an important tool for
              the symbolic analysis of the parameterized domains used to define
              variables and computation domains in PARE's.
              A library of operations on parameterized polyhedra based on the
              Polyhedral Library has been written in C and is freely
              distributed."
}

@Misc{Loechner99,
  Author = "V. Loechner",
  Title = "{\it PolyLib\/}:
           A Library for Manipulating Parameterized Polyhedra",
  Howpublished = "Available at
                  \url{http://icps.u-strasbg.fr/~loechner/polylib/}",
  Year = 1999,
  Month = mar,
  Note = "Declares itself to be a continuation of \cite{Wilde93th}"
}

@InProceedings{Masdupuy92,
  Author = "F. Masdupuy",
  Title = "Array Operations Abstraction Using Semantic Analysis
           of Trapezoid Congruences",
  Booktitle = "Proceedings of the 6th ACM International Conference
               on Supercomputing",
  Address = "Washington, DC, USA",
  Publisher = "ACM Press",
  Pages = "226--235",
  Year = 1992,
  Abstract = "With the growing use of vector supercomputers, efficient
              and accurate data structure analyses are needed. What we
              propose in this paper is to use the quite general
              framework of Cousot's abstract interpretation for the
              particular analysis of multi-dimensional array
              indexes. While such indexes are integer tuples, a
              relational integer analysis is first required. This
              analysis results of a combination of existing ones that
              are interval and congruence based. Two orthogonal
              problems are directly concerned with the results of such
              an analysis, that are the parallelization/vectorization
              with the dependence analysis and the data locality
              problem used for array storage management. After
              introducing the analysis algorithm, this paper describes
              on a complete example how to use it in order to optimize
              array storage."
}

@PhdThesis{Masdupuy93th,
  Author = "F. Masdupuy",
  Title = "Array Indices Relational Semantic Analysis
           Using Rational Cosets and Trapezoids",
  Type = "{Th\`ese d'informatique}",
  School = "\'Ecole Polytechnique",
  Address = "Palaiseau, France",
  Month = dec,
  Year = 1993,
  Abstract = "Semantic analysis of program numerical variables
              consists in statically and automatically discovering
              properties verified at execution time. Different sets of
              properties (equality, inequality and congruence
              relations) have already been studied. This thesis
              proposes a generalization of some of the below
              patterns. More specifically, the abstract interpretation
              is used to design on the one hand a set of properties
              generalizing intervals and cosets on $\mathbbb{Z}$ and
              on the other hand, a generalization of trapezoids and
              linear congruence equation systems on $\mathbbb{Z}^n$.
              A rational abstraction of these properties is defined to
              get safe approximations, with a polynomial complexity in
              the number of the considered variables, of the integer
              properties operators. Those analyses, more precise than
              the combination of the analysis they come from in
              general, allow to dynamically choose the kind of
              properties (inequality or congruence relations) leading
              to relevant information for the considered program. The
              described relationnal analysis corresponds to numerous
              patterns encountered in the field of scientific
              computation.  It is very well adapted to the analysis of
              array indices variables and also to the abstract
              description of integer arrays."
}

@InProceedings{Mine01a,
  Author = "A. Min\'e",
  Title = "A New Numerical Abstract Domain Based on Difference-Bound Matrices",
  Booktitle = "Proceedings of the 2nd Symposium on Programs as Data Objects
               (PADO 2001)",
  Address = "Aarhus, Denmark",
  Editor = "O. Danvy and A. Filinski",
  Publisher = "Springer-Verlag, Berlin",
  Series = "Lecture Notes in Computer Science",
  Volume = 2053,
  Pages = "155--172",
  Year = 2001,
  Abstract = "This paper presents a new numerical domain for static
              analysis by abstract interpretation. This domain allows
              us to represent invariants of the form and , where and
              are variables values and is an integer or real
              constant. Abstract elements are represented by
              Difference-Bound Matrices, widely used by
              model-checkers, but we had to design new operators to
              meet the needs of abstract interpretation. The result is
              a complete lattice of infinite height featuring
              widening, narrowing and common transfer functions. We
              focus on giving an efficient representation and
              graph-based algorithms---where is the number of
              variables---and claim that this domain always performs
              more precisely than the well-known interval domain. To
              illustrate the precision/cost tradeoff of this domain,
              we have implemented simple abstract interpreters for toy
              imperative and parallel languages which allowed us to
              prove some non-trivial algorithms correct."
}

@InProceedings{Mine01b,
  Author = "A. Min\'e",
  Title  = "The Octagon Abstract Domain",
  Booktitle = "Proceedings of the Eighth Working Conference
               on Reverse Engineering (WCRE'01)",
  Address = "Stuttgart, Germany",
  Year = 2001,
  Publisher = "IEEE Computer Society Press",
  Pages = "310--319",
  Abstract = "This article presents a new numerical abstract domain
              for static analysis by abstract interpretation. It
              extends our previously proposed DBM-based numerical
              abstract domain and allows us to represent invariants of
              the form ($\pm x \pm y \leq c$), where $x$ and $y$ are
              program variables and $c$ is a real constant. We focus
              on giving an efficient representation based on
              Difference-Bound Matrices---$\mathcal{O}(n^2)$ memory
              cost, where $n$ is the number of variables---and
              graph-based algorithms for all common abstract
              operators---$\mathcal{O}(n^3)$ time cost. This includes
              a normal form algorithm to test equivalence of
              representation and a widening operator to compute least
              fixpoint approximations."
}

@InProceedings{Mine02,
  Author = "A. Min\'e",
  Title = "A Few Graph-Based Relational Numerical Abstract Domains",
  Booktitle = "Static Analysis:
               Proceedings of the 9th International Symposium",
  Address = "Madrid, Spain",
  Editor = "M. V. Hermenegildo and G. Puebla",
  Publisher = "Springer-Verlag, Berlin",
  Series = "Lecture Notes in Computer Science",
  Volume = 2477,
  ISBN = "3-540-44235-9",
  Pages = "117--132",
  Year = 2002,
  Abstract = "This article presents the systematic design of a class
              of relational numerical abstract domains from
              non-relational ones. Constructed domains represent sets
              of invariants of the form $(v_j-v_i\in C)$, where vj and
              vi are two variables, and $C$ lives in an abstraction of
              $\mathcal{P}(\mathbb {Z})$, $\mathcal{P}(\mathbb {Q})$,
              or $\mathcal{P}(\mathbb {R})$. We will call this family
              of domains weakly relational domains. The underlying
              concept allowing this construction is an extension of
              potential graphs and shortest-path closure algorithms in
              exotic-like algebras.  Example constructions are given
              in order to retrieve well-known domains as well as new
              ones. Such domains can then be used in the Abstract
              Interpretation framework in order to design various
              static analyses. A major benefit of this construction is
              its modularity, allowing to quickly implement new
              abstract domains from existing ones."
}

@InProceedings{Mine04,
  Author = "A. Min\'e",
  Title = "Relational Abstract Domains for the Detection
           of Floating-Point Run-Time Errors",
  Booktitle = "Programming Languages and Systems: Proceedings of the 13th
               European Symposium on Programming",
  Address = "Barcelona, Spain",
  Editor = "D. Schmidt",
  Publisher = "Springer-Verlag, Berlin",
  Series = "Lecture Notes in Computer Science",
  Volume = 2986,
  ISBN = "3-540-213213-9",
  Year = 2004,
  Pages = "3--17",
  Abstract = "We present a new idea to adapt relational abstract
              domains to the analysis of IEEE 754-compliant
              floating-point numbers in order to statically detect,
              through Abstract Interpretation-based static analyses,
              potential floating-point run-time exceptions such as
              overflows or invalid operations. In order to take the
              non-linearity of rounding into account, expressions are
              modeled as linear forms with interval coefficients. We
              show how to extend already existing numerical abstract
              domains, such as the octagon abstract domain, to
              efficiently abstract transfer functions based on
              interval linear forms. We discuss specific fixpoint
              stabilization techniques and give some experimental
              results."
}

@PhdThesis{Mine05th,
  Author = "A. Min\'e",
  Title  = "Weakly Relational Numerical Abstract Domains",
  School = "\'Ecole Polytechnique",
  Address = "Paris, France",
  Month = mar,
  Year   = 2005,
  Abstract = "The goal of this thesis is to design techniques related
              to the automatic analysis of computer programs. One major
              application is the creation of tools to discover bugs
              before they actually happen, an important goal in a time
              when critical yet complex tasks are performed by computers.
              We will work in the Abstract Interpretation framework, a
              theory of sound approximations of program semantics. We
              will focus, in particular, on numerical abstract domains
              that specialise in the automatic discovery of properties
              of the numerical variables of programs. In this thesis,
              we introduce new numerical abstract domains: the zone
              abstract domain (that can discover invariants of the form
              $X - Y \leq c$), the zone congruence domain
              ($X \equiv Y + a [b]$), and the octagon domain
              ($\pm X \pm Y \leq c$), among others. These domains rely
              on the classical notions of potential graphs, difference
              bound matrices, and algorithms for the shortest-path
              closure computation. They are in-between, in terms of
              cost and precision, between nonrelational domains (such
              as the interval domain), that are very imprecise, and
              classical relational domains (such as the polyhedron
              domain), that are very costly. We will call them ``weakly
              relational''. We also introduce some methods to apply
              relational domains to the analysis of floating-point
              numbers, which was previously only possible using
              imprecise, non-relational, domains. Finally, we introduce
              the so-called linearisation and symbolic constant
              propagation generic symbolic methods to enhance the
              precision of any numerical domain, for only a slight
              increase in cost. The techniques presented in this thesis
              have been integrated within Astr\'ee, an analyser for
              critical embedded avionic software, and were instrumental
              in proving the absence of run-time errors in fly-by-wire
              softwares used in Airbus A340 and A380 planes. Experimental
              results show the usability of our methods of real-life
              applications.",
}

@InCollection{MotzkinRTT53,
  Author = "T. S. Motzkin and H. Raiffa and G. L. Thompson and R. M. Thrall",
  Title = "The Double Description Method",
  Booktitle = "Contributions to the Theory of Games -- Volume II",
  Editor = "H. W. Kuhn and A. W. Tucker",
  Series = "Annals of Mathematics Studies",
  Number = 28,
  Publisher = "Princeton University Press",
  Address = "Princeton, New Jersey",
  Year = 1953,
  Pages = "51--73",
  Abstract = "The purpose of this paper is to present a computational
              method for the determination of the value and of all
              solutions of a two-person zero-sum game with a finite
              number of pure strategies, and for the solution of
              general finite systems of linear inequalities and
              corresponding maximization problems."
}

@InProceedings{NelsonO77,
  Author = "G. Nelson and D. C. Oppen",
  Title = "Fast Decision Algorithms based on {Union} and {Find}",
  Booktitle = "Proceedings of the 18th Annual Symposium on Foundations
               of Computer Science (FOCS'77)",
  Address = "Providence, RI, USA",
  Publisher = "IEEE Computer Society Press",
  Pages = "114--119",
  Year = 1977,
  Note = "The journal version of this paper is \cite{NelsonO80}"
}

@Article{NelsonO80,
  Author = "G. Nelson and D. C. Oppen",
  Title = "Fast Decision Procedures Based on Congruence Closure",
  Journal = "Journal of the ACM",
  Publisher = "ACM Press",
  Volume = 27,
  Number = 2,
  Pages = "356--364",
  Year = 1980,
  Note = "An earlier version of this paper is \cite{NelsonO77}",
  Abstract = "The notion of the congruence closure of a relation on a
              graph is defined and several algorithms for computing
              it are surveyed. A simple proof is given that the
              congruence closure algorithm provides a decision
              procedure for the quantifier-free theory of equality. A
              decision procedure is then given for the
              quantifier-free theory of LISP list structure based on
              the congruence closure algorithm. Both decision
              procedures determine the satisfiability of a
              conjunction of literals of length n in average time
              $O(n \log n)$ using the fastest known congruence closure
              algorithm. It is also shown that if the axiomatization
              of the theory of list structure is changed slightly,
              the problem of determining the satisfiability of a
              conjunction of literals becomes NP-complete. The
              decision procedures have been implemented in the
              authors' simplifier for the Stanford Pascal Verifier."
}

@Book{NemhauserW88,
  Author = "G. L. Nemhauser and L. A. Wolsey",
  Title = "Integer and Combinatorial Optimization",
  Publisher = "John Wiley \& Sons",
  Series = "Wiley Interscience Series
            in Discrete Mathematics and Optimization",
  Year = 1988
}

@TechReport{NookalaR00,
  Author = "S. P. K. Nookala and T. Risset",
  Title = "A Library for {Z}-Polyhedral Operations",
  Type = "\emph{Publication interne}",
  Number = 1330,
  Institution = "IRISA",
  Address = "Campus de Beaulieu, Rennes, France",
  Year = 2000,
  Abstract = "Polyhedra are commonly used for representing iteration
              domains of loop nests with unit stride: the iteration
              domain of a loop is associated with the set of integer
              points contained in a polyhedron.  ${\cal Z}$-polyhedra
              are natural extension of polyhedra, in the sense that
              they represent iteration domains of loop nests with
              non-unit stride (they are polyhedra intersected with
              integral lattices). The polyhedral library (Polylib) has
              been developed for computing on polyhedra, it is now
              widely used in the automatic parallelization research
              community. This report describes the implementation of
              the extension of Polylib to ${\cal Z}$-polyhedra. We
              describe algorithms used for computing on lattices and
              ${\cal Z}$-polyhedra, and we provide technical
              documentation for the ${\cal Z}$-polyhedral library
              (data structures, functions available)."
}

@Book{PapadimitriouS98,
  Author = "C. H. Papadimitriou and K. Steiglitz",
  Title = "Combinatorial Optimization: Algorithms and Complexity",
  Edition = "Second",
  Publisher = "Dover Publications",
  ISBN = "0-486-40258-4",
  Year = 1998,
}

@Unpublished{Pratt77,
  Author = "V. R. Pratt",
  Title="Two Easy Theories whose Combination is Hard",
  Note = "Memo sent to Nelson and Oppen
          concerning a preprint of their paper \cite{NelsonO77}",
  Month = sep,
  Year = 1977,
  Abstract = "We restrict attention to the validity problem for
              unquantified disjunctions of literals (possibly negated
              atomic formulae) over the domain of integers, or what is
              just as good, the satisfiability problem for
              unquantified conjunctions. When $=$ is the only
              predicate symbol and all function symbols are left
              uninterpreted, or when $\geq$ is the only predicate
              symbol (taking its standard interpretation on the
              integers) and the only terms are variables and integers,
              then satisfiability is decidable in polynomial
              time. However when $\geq$ and uninterpreted function
              symbols are allowed to appear together, satisfiability
              becomes an NP-complete problem. This combination of the
              two theories can arise for example when reasoning about
              arrays (the uninterpreted function symbols) and
              subscript manipulation (where $\geq$ arises in
              considering subscript bounds). These results are
              unaffected by the presence of successor, which also
              arises commonly in reasoning about subscript
              manipulation."
}

@TechReport{QuintonRR96,
  Author = "P. Quinton and S. Rajopadhye and T. Risset",
  Title = "On Manipulating {Z}-Polyhedra",
  Year = 1996,
  Month = jul,
  Institution = "IRISA, Campus Universitaire de Bealieu, Rennes, France",
  Number = 1016,
  Abstract = "We address the problem of computation upon Z-Polyhedra
             which are intersections of polyhedra and integral
             lattices. We introduce a canonic representation for
             Z-polyhedra which allow to perform comparisons and
             transformations of Z-polyhedra with the help of a
             computational kernal on polyhedra. This contribution is a
             step towards the manipulation of images of polyhedra by
             affine functions, and has application in the domain of
             automatic parallelization and parallel VLSI synthesis.",
}

@Article{QuintonRR97,
  Author = "P. Quinton and S. Rajopadhye and T. Risset",
  Title = "On Manipulating {Z}-Polyhedra Using a Canonic Representation",
  Journal = "Parallel Processing Letters",
  Publisher = "World Scientific Publishing Company",
  Volume = 7,
  Number = 2,
  Pages = "181--194",
  Year = 1997,
  Abstract = "Z-Polyhedra are intersections of polyhedra and integral
             lattices. They arise in the domain of automatic
             parallelization and VLSI array synthesis. In this paper,
             we address the problem of computation on Z-polyhedra.
             We introduce a canonical representation for Z-polyhedra
             which allows one to perform comparisons and transformations
             of Z-polyhedra with the help of a computational kernal on
             polyhedra.",
}

@MastersThesis{Ricci02th,
  Author = "E. Ricci",
  Title = "Rappresentazione e manipolazione di poliedri convessi
           per l'analisi e la verifica di programmi",
  Type = "{Tesi di laurea}",
  School = "Corso di Laurea in Matematica, Universit\`a di Parma",
  Address = "Parma, Italy",
  Month = jul,
  Year = 2002,
  Note = "In Italian",
  URL = "http://www.cs.unipr.it/ppl/Documentation/Ricci02th.pdf"
}

@Article{Shostak81,
  Author = "R. E. Shostak",
  Title = "Deciding Linear Inequalities by Computing Loop Residues",
  Journal = "Journal of the ACM",
  Publisher = "ACM Press",
  Volume = 28,
  Number = 4,
  Pages = "769--779",
  Year = 1981,
  Abstract = "V.~R.~Pratt has shown that the real and integer
              feasibility of sets of linear inequalities of the form
              $x \leq y + c$ can be decided quickly by examining the
              loops in certain graphs.  Pratt's method is generalized,
              first to real feasibility of inequalities in two
              variables and arbitrary coefficients, and ultimately to
              real feasibility of arbitrary sets of linear
              inequalities.  The method is well suited to applications
              in program verification."
}

@Book{Schrijver99,
  Author = "A. Schrijver",
  Title = "Theory of Linear and Integer Programming",
  Publisher = "John Wiley \& Sons",
  Series = "Wiley Interscience Series
            in Discrete Mathematics and Optimization",
  ISBN = "0-471-98232-6",
  Year = 1999
}

@Article{Srivastava93,
  Author = "D. Srivastava",
  Title = "Subsumption and Indexing in Constraint Query Languages
           with Linear Arithmetic Constraints",
  Journal = "Annals of Mathematics and Artificial Intelligence",
  Volume = 8,
  Number = "3--4",
  Pages = "315--343",
  Year = 1993,
  Abstract = "Bottom-up evaluation of a program-query pair in a
              constraint query language (CQL) starts with the facts in
              the database and repeatedly applies the rules of the
              program, in iterations, to compute new facts, until we
              have reached a fixpoint.  Checking if a fixpoint has
              been reached amounts to checking if any ``new'' facts
              were computed in an iteration.  Such a check also
              enhances efficiency in that subsumed facts can be
              discarded, and not be used to make any further
              derivations in subsequent iterations, if we use
              Semi-naive evaluation.
              We show that the problem of subsumption in CQLs with
              linear arithmetic constraints is co-NP complete, and
              present a deterministic algorithm, based on the divide
              and conquer strategy, for this problem.  We also
              identify polynomial-time sufficient conditions for
              subsumption and non-subsumption in CQLs with linear
              arithmetic constraints.  We adapt indexing strategies
              from spatial databases for efficiently indexing facts in
              such a CQL: such indexing is crucial for performance in
              the presence of large databases.  Based on a recent
              algorithm by Lassez and Lassez [LL] for quantifier
              elimination, we present an incremental version of the
              algorithm to check for subsumption in CQLs with linear
              arithmetic constraints.",
  URL = "http://www.research.att.com/~divesh/papers/s93-cqlsubsum-journal.ps"
}

@Book{StoerW70,
  Author = "J. Stoer and C. Witzgall",
  Title = "Convexity and Optimization in Finite Dimensions I",
  Publisher = "Springer-Verlag, Berlin",
  Year = 1970
}

@MastersThesis{Wilde93th,
  Author = "D. K. Wilde",
  Title = "A Library for Doing Polyhedral Operations",
  Type = "{Master's thesis}",
  School = "Oregon State University",
  Address = "Corvallis, Oregon",
  Month = dec,
  Year = 1993,
  Note = "Also published as IRISA \emph{Publication interne} 785,
          Rennes, France, 1993",
  Abstract = "Polyhedra are geometric representations of linear
              systems of equations and inequalities.  Since polyhedra
              are used to represent the iteration domains of nested
              loop programs, procedures for operating on polyhedra are
              useful for doing loop transformations and other program
              restructuring transformations which are needed in
              parallelizing compilers.  Thus a need for a library of
              polyhedral operations has recently been recognized in
              the parallelizing compiler community.  Polyhedra are
              also used in the definition of domains of variables in
              systems of affine recurrence equations (SARE). {\sc
              Alpha} is a language which is based on the SARE
              formalism in which all variables are declared over
              finite unions of polyhedra.  This report describes a
              library of polyhedral functions which was developed to
              support the {\sc Alpha} language environment, and which
              is general enough to satisfy the needs of researchers
              doing parallelizing compilers.  This report describes
              the data structures used to represent domains, gives
              motivations for the major design decisions, and presents
              the algorithms used for doing polyhedral operations.
              This library has been written and tested, and has been
              in use since the beginning of 1993 by research
              facilities in Europe and Canada.  The library is freely
              distributed by ftp.",
  URL = "http://www.irisa.fr/polylib/document/Polylib.ps"
}

@Article{Weyl35,
  Author = "H. Weyl",
  Title = "Elementare Theorie der konvexen Polyeder",
  Journal = "Commentarii Mathematici Helvetici",
  Publisher = "{Birkh\"auser} Publishing Ltd., Basel, Switzerland",
  Volume = 7,
  Pages = "290--306",
  Year = 1935,
  Note = "English translation in \cite{Weyl50}"
}

@InCollection{Weyl50,
  Author = "H. Weyl",
  Title = "The Elementary Theory of Convex Polyhedra",
  Booktitle = "Contributions to the Theory of Games -- Volume I",
  Editor = "H. W. Kuhn",
  Series = "Annals of Mathematics Studies",
  Number = 24,
  Publisher = "Princeton University Press",
  Address = "Princeton, New Jersey",
  Year = 1950,
  Pages = "3--18",
  Note = "Translated from \cite{Weyl35} by H. W. Kuhn"
}
